{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ba7d7c-7b78-457b-a8bf-d458a243b37f",
   "metadata": {},
   "source": [
    "# extract table from wikepedia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b25b0d2e-f292-482a-b8e8-9e26054b2794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Wikipedia page URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_craters_on_Mercury\"\n",
    "\n",
    "# Fetch the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all tables with class \"wikitable\"\n",
    "    tables = soup.find_all(\"table\", class_=\"wikitable\")\n",
    "\n",
    "    # Store all tables\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate through all tables\n",
    "    for table_index, table in enumerate(tables):\n",
    "        table_data = []\n",
    "\n",
    "        # Extract data from each row\n",
    "        for row in table.find_all(\"tr\")[1:]: \n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) >= 5:  \n",
    "                name = cols[0].text.strip()\n",
    "                diameter = cols[1].text.strip()\n",
    "                coordinates = cols[2].text.strip()\n",
    "                approval_year = cols[3].text.strip()\n",
    "                eponym = cols[4].text.strip()\n",
    "\n",
    "                # Extract link\n",
    "                link_tag = cols[5].find(\"a\") if len(cols) > 5 else None\n",
    "                link = f\"https://en.wikipedia.org{link_tag['href']}\" if link_tag else \"No link\"\n",
    "\n",
    "                table_data.append([name, diameter, coordinates, approval_year, eponym, link])\n",
    "\n",
    "        df = pd.DataFrame(table_data, columns=[\"Name\", \"Diameter\", \"Coordinates\", \"Approval Year\", \"Eponym\", \"Link\"])\n",
    "        \n",
    "        all_data.append(df)\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df.to_csv(\"mercury_craters.csv\", index=False)\n",
    "    print(\"CSV saved\")\n",
    "                        \n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd305a92-564b-4293-8f67-7006ce2c08ae",
   "metadata": {},
   "source": [
    "## extract nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686e3e4-56e6-4866-bc38-f9be12880a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
